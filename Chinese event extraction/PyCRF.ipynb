{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pycrfsuite\n",
    "import codecs\n",
    "import numpy as np\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from itertools import chain\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txt_name = ['trigger_train', 'argument_train', 'trigger_test','argument_test']\n",
    "txt = []\n",
    "for i in txt_name:\n",
    "    f = codecs.open(i+'.txt', 'r', 'utf8')\n",
    "    txt.append(f.readlines())\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#txt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef get_corpus(trigger_train, argument_train):\\n    trigger_train = [each.split() for each in trigger_train]\\n    argument_train = [each.split() for each in argument_train]\\n    new_list = []\\n    in_list = []\\n    for each1, each2 in zip(trigger_train, argument_train):\\n        print(each1, each2)\\n        if each1 != []:\\n            in_list.append(each1.append(each2[1])) \\n        else:\\n            new_list.append(in_list)\\n            in_list = []  \\n    return new_list\\ntrain = get_corpus(txt[0], txt[1])\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def get_corpus(trigger_train, argument_train):\n",
    "    trigger_train = [each.split() for each in trigger_train]\n",
    "    argument_train = [each.split() for each in argument_train]\n",
    "    new_list = []\n",
    "    in_list = []\n",
    "    for each1, each2 in zip(trigger_train, argument_train):\n",
    "        print(each1, each2)\n",
    "        if each1 != []:\n",
    "            in_list.append(each1.append(each2[1])) \n",
    "        else:\n",
    "            new_list.append(in_list)\n",
    "            in_list = []  \n",
    "    return new_list\n",
    "train = get_corpus(txt[0], txt[1])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_corpus(data):\n",
    "    data = [each.split() for each in data]\n",
    "    new_list = []\n",
    "    in_list = []\n",
    "    for each in data:\n",
    "        if each != []:\n",
    "            in_list.append(each) \n",
    "        else:\n",
    "            new_list.append(in_list)\n",
    "            in_list = []  \n",
    "    return new_list\n",
    "txt = [get_corpus(each) for each in txt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['跨', 'O'],\n",
       " ['党派', 'O'],\n",
       " ['大陆', 'O'],\n",
       " ['台商', 'O'],\n",
       " ['权益', 'O'],\n",
       " ['促进会', 'O'],\n",
       " ['6', 'O'],\n",
       " ['号', 'O'],\n",
       " ['成立', 'T_Business']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(word):\n",
    "    p = pseg.cut(word)\n",
    "    flag = 0\n",
    "    for i in p:\n",
    "        pos = i.flag\n",
    "        flag += 1\n",
    "    if flag != 1:\n",
    "        pos = ''\n",
    "    return pos\n",
    "\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    features = [\n",
    "        #'bias',\n",
    "        #'word.length=%s' % len(word),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        #'word[-1]=' + word[-1],\n",
    "        #'word[0]=' + word[0],\n",
    "        'word=' + word,\n",
    "    ]\n",
    "    if pos(word) != '':\n",
    "        features.append('pos=' + pos(word))\n",
    "        if len(pos(word)) > 1:\n",
    "            features.extend(['pos[0]=' + pos(word)[0], 'pos[1:]=' + pos(word)[1:]])\n",
    "#############################\n",
    "    if i > 0:\n",
    "        word = sent[i-1][0]\n",
    "        features.extend([\n",
    "            #'-1:word.length=%s' % len(word),\n",
    "            #'-1:word.isdigit=%s' % word.isdigit(),\n",
    "            '-1:word=' + word,\n",
    "            #'-1:word[-1]=' + word[-1],\n",
    "            #'-1:word[0]=' + word[0],\n",
    "        ])\n",
    "        if pos(word) != '':\n",
    "            features.append('-1:pos=' + pos(word))\n",
    "            if len(pos(word)) > 1:\n",
    "                features.extend(['-1:pos[0]=' + pos(word)[0], '-1:pos[1:]=' + pos(word)[1:]])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "##################################\n",
    "    if i < len(sent)-1:\n",
    "        word = sent[i+1][0]\n",
    "        features.extend([\n",
    "            #'+1:word.length=%s' % len(word),\n",
    "            #'+1:word.isdigit=%s' % word.isdigit(),\n",
    "            '+1:word=' + word,\n",
    "            #'+1:word[-1]=' + word[-1],\n",
    "            #'+1:word[0]=' + word[0],\n",
    "        ])\n",
    "        if pos(word) != '':\n",
    "            features.append('+1:pos=' + pos(word))\n",
    "            if len(pos(word)) > 1:\n",
    "                features.extend(['+1:pos[0]=' + pos(word)[0], '+1:pos[1:]=' + pos(word)[1:]])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "    return features\n",
    "'''\n",
    "#################################\n",
    "    if i > 1:\n",
    "        word = sent[i-2][0]\n",
    "        features.extend([\n",
    "            #'-2:word.length=%s' % len(word),\n",
    "            '-2:word.isdigit=%s' % word.isdigit(),\n",
    "            #'-2:word=' + word,\n",
    "            #'-2:word[-1]=' + word[-1],\n",
    "            #'-2:word[0]=' + word[0],\n",
    "        ])\n",
    "        if pos(word) != '':\n",
    "            features.extend(['-2:pos=' + pos(word),'-2:pos[0]=' + pos(word)[0]])\n",
    "    else:\n",
    "        features.append('BOS1')\n",
    "#################################\n",
    "    if i < len(sent)-2:\n",
    "        word = sent[i+2][0]\n",
    "        features.extend([\n",
    "            #'+2:word.length=%s' % len(word),\n",
    "            '+2:word.isdigit=%s' % word.isdigit(),\n",
    "            #'+2:word=' + word,\n",
    "            #'+2:word[-1]=' + word[-1],\n",
    "            #'+2:word[0]=' + word[0],\n",
    "        ])\n",
    "        if pos(word) != '':\n",
    "            features.extend(['+2:pos=' + pos(word),'+2:pos[0]=' + pos(word)[0]])\n",
    "    else:\n",
    "        features.append('EOS1')\n",
    "#################################\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# txt_name = ['trigger_train', 'argument_train', 'trigger_test','argument_test']\n",
    "\n",
    "x_trigger_train = [sent2features(s) for s in txt[0]]\n",
    "y_trigger_train = [sent2labels(s) for s in txt[0]]\n",
    "\n",
    "x_trigger_test = [sent2features(s) for s in txt[2]]\n",
    "y_trigger_test = [sent2labels(s) for s in txt[2]]\n",
    "\n",
    "x_argument_train = [sent2features(s) for s in txt[1]]\n",
    "y_argument_train = [sent2labels(s) for s in txt[1]]\n",
    "\n",
    "x_argument_test = [sent2features(s) for s in txt[3]]\n",
    "y_argument_test = [sent2labels(s) for s in txt[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word.isdigit=False',\n",
       " 'word=南斯拉夫',\n",
       " 'pos=nrt',\n",
       " 'pos[0]=n',\n",
       " 'pos[1:]=rt',\n",
       " 'BOS',\n",
       " '+1:word=反对党',\n",
       " '+1:pos=n']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_trigger_train[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CRF(x_train, y_train, x_test, model_name):\n",
    "    trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "    for xseq, yseq in zip(x_train, y_train):\n",
    "        trainer.append(xseq, yseq)\n",
    "\n",
    "    trainer.set_params({\n",
    "        'c1': 1.0,   # coefficient for L1 penalty\n",
    "        'c2': 1e-3,  # coefficient for L2 penalty\n",
    "        'max_iterations': 50,  # stop earlier\n",
    "\n",
    "        # include transitions that are possible, but not observed\n",
    "        'feature.possible_transitions': True\n",
    "    })\n",
    "\n",
    "    trainer.train(model_name + '.crfsuite')\n",
    "\n",
    "    #print(trainer.logparser.last_iteration)\n",
    "    \n",
    "    tagger = pycrfsuite.Tagger()\n",
    "    tagger.open(model_name + '.crfsuite')\n",
    "    '''\n",
    "    if model_name == 'trigger':\n",
    "        i = 2\n",
    "    else: i = 3 \n",
    "    example_sent = txt[i][13]\n",
    "    print(' '.join(sent2tokens(example_sent)), end='\\n\\n')\n",
    "\n",
    "    print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
    "    print(\"Correct:  \", ' '.join(sent2labels(example_sent)))\n",
    "    '''\n",
    "    y_pred = [tagger.tag(xseq) for xseq in x_test]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_trigger_pred = CRF(x_trigger_train, y_trigger_train, x_trigger_test, 'trigger')\n",
    "y_argument_pred = CRF(x_argument_train, y_argument_train, x_argument_test, 'argument')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_example(K, model_name='trigger', txt = txt):\n",
    "    tagger = pycrfsuite.Tagger()\n",
    "    tagger.open(model_name + '.crfsuite')\n",
    "\n",
    "    if model_name == 'trigger':\n",
    "        i = 2\n",
    "    else: i = 3 \n",
    "    example_sent = txt[i][K]\n",
    "    print(' '.join(sent2tokens(example_sent)), end='\\n\\n')\n",
    "\n",
    "    print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
    "    print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J 君 的 本 本领 了 好几年 ， 可 就是 没车 开 。 那天 打电话 告诉 我 ， 买\n",
      "\n",
      "Predicted: O O O O O O O O O O O O O O T_Contact O O O T_Transaction\n",
      "Correct:   O O O O O O O O O O O O O O O O O O T_Transaction\n",
      "出售 国营 公司\n",
      "\n",
      "Predicted: A_Org A_Org A_Org\n",
      "Correct:   O A_Artifact A_Artifact\n"
     ]
    }
   ],
   "source": [
    "K = np.random.randint(len(y_trigger_pred))\n",
    "test_example(K, model_name='trigger')\n",
    "test_example(K, model_name='argument')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "   T_Business       0.87      0.65      0.74        31\n",
      "   T_Conflict       0.71      0.62      0.66       135\n",
      "    T_Contact       0.97      0.48      0.64        58\n",
      "    T_Justice       0.73      0.58      0.65       141\n",
      "       T_Life       0.83      0.75      0.79        72\n",
      "   T_Movement       0.81      0.68      0.74       146\n",
      "  T_Personnel       0.91      0.34      0.50        88\n",
      "T_Transaction       0.54      0.50      0.52        14\n",
      "\n",
      "  avg / total       0.80      0.59      0.67       685\n",
      "\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      A_Adjudicator       0.66      0.54      0.60       144\n",
      "            A_Agent       0.16      0.23      0.19       190\n",
      "         A_Artifact       0.14      0.25      0.18       374\n",
      "         A_Attacker       0.38      0.11      0.17       265\n",
      "      A_Beneficiary       0.00      0.00      0.00        39\n",
      "            A_Buyer       0.00      0.00      0.00        12\n",
      "            A_Crime       0.24      0.03      0.06       128\n",
      "        A_Defendant       0.17      0.09      0.12       256\n",
      "      A_Destination       0.58      0.55      0.56       319\n",
      "           A_Entity       0.35      0.20      0.25       407\n",
      "            A_Giver       0.50      0.35      0.41        17\n",
      "       A_Instrument       0.59      0.14      0.22       116\n",
      "            A_Money       0.23      0.40      0.29        20\n",
      "              A_Org       0.22      0.25      0.23       135\n",
      "           A_Origin       0.66      0.28      0.39        82\n",
      "           A_Person       0.16      0.19      0.17       451\n",
      "            A_Place       0.43      0.41      0.42       410\n",
      "        A_Plaintiff       0.75      0.04      0.08        68\n",
      "         A_Position       0.67      0.14      0.23       142\n",
      "            A_Price       0.00      0.00      0.00         2\n",
      "       A_Prosecutor       0.00      0.00      0.00        58\n",
      "        A_Recipient       0.00      0.00      0.00        29\n",
      "           A_Seller       0.00      0.00      0.00        10\n",
      "         A_Sentence       0.28      0.44      0.34        50\n",
      "           A_Target       0.24      0.15      0.19       312\n",
      "          A_Vehicle       0.27      0.20      0.23        60\n",
      "           A_Victim       0.36      0.43      0.39       299\n",
      "       A_Time-After       0.00      0.00      0.00        27\n",
      "A_Time-At-Beginning       0.00      0.00      0.00         6\n",
      "      A_Time-At-End       0.00      0.00      0.00         7\n",
      "      A_Time-Before       0.62      0.16      0.26        31\n",
      "      A_Time-Ending       0.00      0.00      0.00         8\n",
      "       A_Time-Holds       0.34      0.35      0.35        37\n",
      "    A_Time-Starting       0.56      0.63      0.59        30\n",
      "      A_Time-Within       0.62      0.71      0.66       703\n",
      "\n",
      "        avg / total       0.37      0.31      0.32      5244\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(bio_classification_report(y_trigger_test, y_trigger_pred))\n",
    "print(bio_classification_report(y_argument_test, y_argument_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
